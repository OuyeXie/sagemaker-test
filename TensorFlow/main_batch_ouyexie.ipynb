{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the environment¶\n",
    "\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.session import Session\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "region = sagemaker_session.boto_session.region_name\n",
    "\n",
    "role = get_execution_role()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-2-181bd7295c81>:7: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:252: _internal_retry.<locals>.wrap.<locals>.wrapped_fn (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use urllib or similar directly.\n",
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting data/train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting data/train-labels-idx1-ubyte.gz\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting data/t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "Writing data/train.tfrecords\n",
      "WARNING:tensorflow:From /home/ec2-user/SageMaker/sagemaker-test/TensorFlow/utils.py:29: The name tf.python_io.TFRecordWriter is deprecated. Please use tf.io.TFRecordWriter instead.\n",
      "\n",
      "Writing data/validation.tfrecords\n",
      "Writing data/test.tfrecords\n"
     ]
    }
   ],
   "source": [
    "#Download the MNIST dataset¶\n",
    "\n",
    "import utils\n",
    "from tensorflow.contrib.learn.python.learn.datasets import mnist\n",
    "import tensorflow as tf\n",
    "\n",
    "data_sets = mnist.read_data_sets('data', dtype=tf.uint8, reshape=False, validation_size=5000)\n",
    "\n",
    "utils.convert_to(data_sets.train, 'train', 'data')\n",
    "utils.convert_to(data_sets.validation, 'validation', 'data')\n",
    "utils.convert_to(data_sets.test, 'test', 'data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload the data¶\n",
    "\n",
    "inputs = sagemaker_session.upload_data(path='data', key_prefix='data/DEMO-mnist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import os\n",
      "import tensorflow as tf\n",
      "from tensorflow.python.estimator.model_fn import ModeKeys as Modes\n",
      "\n",
      "INPUT_TENSOR_NAME = 'inputs'\n",
      "SIGNATURE_NAME = 'predictions'\n",
      "\n",
      "LEARNING_RATE = 0.001\n",
      "\n",
      "\n",
      "def model_fn(features, labels, mode, params):\n",
      "    # Input Layer\n",
      "    input_layer = tf.reshape(features[INPUT_TENSOR_NAME], [-1, 28, 28, 1])\n",
      "\n",
      "    # Convolutional Layer #1\n",
      "    conv1 = tf.layers.conv2d(\n",
      "        inputs=input_layer,\n",
      "        filters=32,\n",
      "        kernel_size=[5, 5],\n",
      "        padding='same',\n",
      "        activation=tf.nn.relu)\n",
      "\n",
      "    # Pooling Layer #1\n",
      "    pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=[2, 2], strides=2)\n",
      "\n",
      "    # Convolutional Layer #2 and Pooling Layer #2\n",
      "    conv2 = tf.layers.conv2d(\n",
      "        inputs=pool1,\n",
      "        filters=64,\n",
      "        kernel_size=[5, 5],\n",
      "        padding='same',\n",
      "        activation=tf.nn.relu)\n",
      "    pool2 = tf.layers.max_pooling2d(inputs=conv2, pool_size=[2, 2], strides=2)\n",
      "\n",
      "    # Dense Layer\n",
      "    pool2_flat = tf.reshape(pool2, [-1, 7 * 7 * 64])\n",
      "    dense = tf.layers.dense(inputs=pool2_flat, units=1024, activation=tf.nn.relu)\n",
      "    dropout = tf.layers.dropout(\n",
      "        inputs=dense, rate=0.4, training=(mode == Modes.TRAIN))\n",
      "\n",
      "    # Logits Layer\n",
      "    logits = tf.layers.dense(inputs=dropout, units=10)\n",
      "\n",
      "    # Define operations\n",
      "    if mode in (Modes.PREDICT, Modes.EVAL):\n",
      "        predicted_indices = tf.argmax(input=logits, axis=1)\n",
      "        probabilities = tf.nn.softmax(logits, name='softmax_tensor')\n",
      "\n",
      "    if mode in (Modes.TRAIN, Modes.EVAL):\n",
      "        global_step = tf.train.get_or_create_global_step()\n",
      "        label_indices = tf.cast(labels, tf.int32)\n",
      "        loss = tf.losses.softmax_cross_entropy(\n",
      "            onehot_labels=tf.one_hot(label_indices, depth=10), logits=logits)\n",
      "        tf.summary.scalar('OptimizeLoss', loss)\n",
      "\n",
      "    if mode == Modes.PREDICT:\n",
      "        predictions = {\n",
      "            'classes': predicted_indices,\n",
      "            'probabilities': probabilities\n",
      "        }\n",
      "        export_outputs = {\n",
      "            SIGNATURE_NAME: tf.estimator.export.PredictOutput(predictions)\n",
      "        }\n",
      "        return tf.estimator.EstimatorSpec(\n",
      "            mode, predictions=predictions, export_outputs=export_outputs)\n",
      "\n",
      "    if mode == Modes.TRAIN:\n",
      "        optimizer = tf.train.AdamOptimizer(learning_rate=0.001)\n",
      "        train_op = optimizer.minimize(loss, global_step=global_step)\n",
      "        return tf.estimator.EstimatorSpec(mode, loss=loss, train_op=train_op)\n",
      "\n",
      "    if mode == Modes.EVAL:\n",
      "        eval_metric_ops = {\n",
      "            'accuracy': tf.metrics.accuracy(label_indices, predicted_indices)\n",
      "        }\n",
      "        return tf.estimator.EstimatorSpec(\n",
      "            mode, loss=loss, eval_metric_ops=eval_metric_ops)\n",
      "\n",
      "\n",
      "def serving_input_fn(params):\n",
      "    inputs = {INPUT_TENSOR_NAME: tf.placeholder(tf.float32, [None, 784])}\n",
      "    return tf.estimator.export.ServingInputReceiver(inputs, inputs)\n",
      "\n",
      "\n",
      "def read_and_decode(filename_queue):\n",
      "    reader = tf.TFRecordReader()\n",
      "    _, serialized_example = reader.read(filename_queue)\n",
      "\n",
      "    features = tf.parse_single_example(\n",
      "        serialized_example,\n",
      "        features={\n",
      "            'image_raw': tf.FixedLenFeature([], tf.string),\n",
      "            'label': tf.FixedLenFeature([], tf.int64),\n",
      "        })\n",
      "\n",
      "    image = tf.decode_raw(features['image_raw'], tf.uint8)\n",
      "    image.set_shape([784])\n",
      "    image = tf.cast(image, tf.float32) * (1. / 255)\n",
      "    label = tf.cast(features['label'], tf.int32)\n",
      "\n",
      "    return image, label\n",
      "\n",
      "\n",
      "def train_input_fn(training_dir, params):\n",
      "    return _input_fn(training_dir, 'train.tfrecords', batch_size=100)\n",
      "\n",
      "\n",
      "def eval_input_fn(training_dir, params):\n",
      "    return _input_fn(training_dir, 'test.tfrecords', batch_size=100)\n",
      "\n",
      "\n",
      "def _input_fn(training_dir, training_filename, batch_size=100):\n",
      "    test_file = os.path.join(training_dir, training_filename)\n",
      "    filename_queue = tf.train.string_input_producer([test_file])\n",
      "\n",
      "    image, label = read_and_decode(filename_queue)\n",
      "    images, labels = tf.train.batch(\n",
      "        [image, label], batch_size=batch_size,\n",
      "        capacity=1000 + 3 * batch_size)\n",
      "\n",
      "    return {INPUT_TENSOR_NAME: images}, labels\n",
      "\n",
      "def neo_preprocess(payload, content_type):\n",
      "    import logging\n",
      "    import numpy as np\n",
      "    import io\n",
      "\n",
      "    logging.info('Invoking user-defined pre-processing function')\n",
      "\n",
      "    if content_type != 'application/x-image' and content_type != 'application/vnd+python.numpy+binary':\n",
      "        raise RuntimeError('Content type must be application/x-image or application/vnd+python.numpy+binary')\n",
      "    \n",
      "    f = io.BytesIO(payload)\n",
      "    image = np.load(f)*255\n",
      "\n",
      "    return image\n",
      "\n",
      "### NOTE: this function cannot use MXNet\n",
      "def neo_postprocess(result):\n",
      "    import logging\n",
      "    import numpy as np\n",
      "    import json\n",
      "\n",
      "    logging.info('Invoking user-defined post-processing function')\n",
      "    \n",
      "    # Softmax (assumes batch size 1)\n",
      "    result = np.squeeze(result)\n",
      "    result_exp = np.exp(result - np.max(result))\n",
      "    result = result_exp / np.sum(result_exp)\n",
      "\n",
      "    response_body = json.dumps(result.tolist())\n",
      "    content_type = 'application/json'\n",
      "\n",
      "    return response_body, content_type\n"
     ]
    }
   ],
   "source": [
    "# Construct a script for distributed training\n",
    "\n",
    "!cat 'mnist.py'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tensorflow py2 container will be deprecated soon.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-12-24 00:47:51 Starting - Starting the training job...\n",
      "2019-12-24 00:47:53 Starting - Launching requested ML instances...\n",
      "2019-12-24 00:48:51 Starting - Preparing the instances for training............\n",
      "2019-12-24 00:50:50 Downloading - Downloading input data\n",
      "2019-12-24 00:50:50 Training - Downloading the training image..\u001b[34m2019-12-24 00:51:02,933 INFO - root - running container entrypoint\u001b[0m\n",
      "\u001b[34m2019-12-24 00:51:02,933 INFO - root - starting train task\u001b[0m\n",
      "\u001b[34m2019-12-24 00:51:02,946 INFO - container_support.training - Training starting\u001b[0m\n",
      "\u001b[34mDownloading s3://sagemaker-us-east-2-371990375707/sagemaker-tensorflow-2019-12-24-00-47-51-105/source/sourcedir.tar.gz to /tmp/script.tar.gz\u001b[0m\n",
      "\u001b[34m2019-12-24 00:51:05,743 INFO - tf_container - ----------------------TF_CONFIG--------------------------\u001b[0m\n",
      "\u001b[34m2019-12-24 00:51:05,743 INFO - tf_container - {\"environment\": \"cloud\", \"cluster\": {\"worker\": [\"algo-2:2222\"], \"ps\": [\"algo-1:2223\", \"algo-2:2223\"], \"master\": [\"algo-1:2222\"]}, \"task\": {\"index\": 0, \"type\": \"master\"}}\u001b[0m\n",
      "\u001b[34m2019-12-24 00:51:05,743 INFO - tf_container - ---------------------------------------------------------\u001b[0m\n",
      "\u001b[34m2019-12-24 00:51:05,743 INFO - tf_container - creating RunConfig:\u001b[0m\n",
      "\u001b[34m2019-12-24 00:51:05,744 INFO - tf_container - {'save_checkpoints_secs': 300}\u001b[0m\n",
      "\u001b[34m2019-12-24 00:51:05,744 INFO - tensorflow - TF_CONFIG environment variable: {u'environment': u'cloud', u'cluster': {u'ps': [u'algo-1:2223', u'algo-2:2223'], u'worker': [u'algo-2:2222'], u'master': [u'algo-1:2222']}, u'task': {u'index': 0, u'type': u'master'}}\u001b[0m\n",
      "\u001b[34m2019-12-24 00:51:05,745 INFO - tf_container - creating an estimator from the user-provided model_fn\u001b[0m\n",
      "\u001b[34m2019-12-24 00:51:05,745 INFO - tensorflow - Using config: {'_save_checkpoints_secs': 300, '_keep_checkpoint_max': 5, '_task_type': u'master', '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fdffaf9cfd0>, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 2, '_tf_random_seed': None, '_device_fn': None, '_num_worker_replicas': 2, '_task_id': 0, '_log_step_count_steps': 100, '_evaluation_master': '', '_eval_distribute': None, '_train_distribute': None, '_session_config': device_filters: \"/job:ps\"\u001b[0m\n",
      "\u001b[34mdevice_filters: \"/job:master\"\u001b[0m\n",
      "\u001b[34mallow_soft_placement: true\u001b[0m\n",
      "\u001b[34mgraph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34m, '_global_id_in_cluster': 0, '_is_chief': True, '_protocol': None, '_save_checkpoints_steps': None, '_experimental_distribute': None, '_save_summary_steps': 100, '_model_dir': u's3://sagemaker-us-east-2-371990375707/sagemaker-tensorflow-2019-12-24-00-47-51-105/checkpoints', '_master': u'grpc://algo-1:2222'}\u001b[0m\n",
      "\u001b[34m2019-12-24 00:51:05,747 INFO - tensorflow - Not using Distribute Coordinator.\u001b[0m\n",
      "\u001b[34m2019-12-24 00:51:05,747 INFO - tensorflow - Start Tensorflow server.\u001b[0m\n",
      "\u001b[34m2019-12-24 00:51:05,987 WARNING - tensorflow - From /opt/ml/code/mnist.py:114: string_input_producer (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mQueue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensor_slices(string_tensor).shuffle(tf.shape(input_tensor, out_type=tf.int64)[0]).repeat(num_epochs)`. If `shuffle=False`, omit the `.shuffle(...)`.\u001b[0m\n",
      "\u001b[34m2019-12-24 00:51:05,997 WARNING - tensorflow - From /usr/local/lib/python2.7/dist-packages/tensorflow/python/training/input.py:276: input_producer (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mQueue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensor_slices(input_tensor).shuffle(tf.shape(input_tensor, out_type=tf.int64)[0]).repeat(num_epochs)`. If `shuffle=False`, omit the `.shuffle(...)`.\u001b[0m\n",
      "\u001b[34m2019-12-24 00:51:05,998 WARNING - tensorflow - From /usr/local/lib/python2.7/dist-packages/tensorflow/python/training/input.py:188: limit_epochs (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mQueue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensors(tensor).repeat(num_epochs)`.\u001b[0m\n",
      "\u001b[34m2019-12-24 00:51:06,001 WARNING - tensorflow - From /usr/local/lib/python2.7/dist-packages/tensorflow/python/training/input.py:197: __init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mTo construct input pipelines, use the `tf.data` module.\u001b[0m\n",
      "\u001b[34m2019-12-24 00:51:06,002 WARNING - tensorflow - From /usr/local/lib/python2.7/dist-packages/tensorflow/python/training/input.py:197: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mTo construct input pipelines, use the `tf.data` module.\u001b[0m\n",
      "\u001b[34m2019-12-24 00:51:06,007 WARNING - tensorflow - From /opt/ml/code/mnist.py:86: __init__ (from tensorflow.python.ops.io_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mQueue-based input pipelines have been replaced by `tf.data`. Use `tf.data.TFRecordDataset`.\u001b[0m\n",
      "\u001b[34m2019-12-24 00:51:06,017 WARNING - tensorflow - From /opt/ml/code/mnist.py:119: batch (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mQueue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.batch(batch_size)` (or `padded_batch(...)` if `dynamic_pad=True`).\u001b[0m\n",
      "\u001b[34m2019-12-24 00:51:06,027 INFO - tensorflow - Calling model_fn.\u001b[0m\n",
      "\u001b[34m2019-12-24 00:51:06,337 INFO - tensorflow - Done calling model_fn.\u001b[0m\n",
      "\u001b[34m2019-12-24 00:51:06,339 INFO - tensorflow - Create CheckpointSaverHook.\u001b[0m\n",
      "\u001b[34m2019-12-24 00:51:06,692 INFO - tensorflow - Graph was finalized.\u001b[0m\n",
      "\u001b[34m2019-12-24 00:51:07,041 INFO - tensorflow - Running local_init_op.\u001b[0m\n",
      "\u001b[34m2019-12-24 00:51:07,046 INFO - tensorflow - Done running local_init_op.\u001b[0m\n",
      "\u001b[34m2019-12-24 00:51:07,075 WARNING - tensorflow - From /usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py:804: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mTo construct input pipelines, use the `tf.data` module.\u001b[0m\n",
      "\u001b[34m2019-12-24 00:51:07,588 INFO - tensorflow - Saving checkpoints for 0 into s3://sagemaker-us-east-2-371990375707/sagemaker-tensorflow-2019-12-24-00-47-51-105/checkpoints/model.ckpt.\u001b[0m\n",
      "\n",
      "2019-12-24 00:51:03 Training - Training image download completed. Training in progress.\u001b[35m2019-12-24 00:51:03,585 INFO - root - running container entrypoint\u001b[0m\n",
      "\u001b[35m2019-12-24 00:51:03,586 INFO - root - starting train task\u001b[0m\n",
      "\u001b[35m2019-12-24 00:51:03,599 INFO - container_support.training - Training starting\u001b[0m\n",
      "\u001b[35mDownloading s3://sagemaker-us-east-2-371990375707/sagemaker-tensorflow-2019-12-24-00-47-51-105/source/sourcedir.tar.gz to /tmp/script.tar.gz\u001b[0m\n",
      "\u001b[35m2019-12-24 00:51:06,445 INFO - tf_container - ----------------------TF_CONFIG--------------------------\u001b[0m\n",
      "\u001b[35m2019-12-24 00:51:06,445 INFO - tf_container - {\"environment\": \"cloud\", \"cluster\": {\"worker\": [\"algo-2:2222\"], \"ps\": [\"algo-1:2223\", \"algo-2:2223\"], \"master\": [\"algo-1:2222\"]}, \"task\": {\"index\": 0, \"type\": \"worker\"}}\u001b[0m\n",
      "\u001b[35m2019-12-24 00:51:06,445 INFO - tf_container - ---------------------------------------------------------\u001b[0m\n",
      "\u001b[35m2019-12-24 00:51:06,446 INFO - tf_container - creating RunConfig:\u001b[0m\n",
      "\u001b[35m2019-12-24 00:51:06,446 INFO - tf_container - {'save_checkpoints_secs': 300}\u001b[0m\n",
      "\u001b[35m2019-12-24 00:51:06,446 INFO - tensorflow - TF_CONFIG environment variable: {u'environment': u'cloud', u'cluster': {u'ps': [u'algo-1:2223', u'algo-2:2223'], u'worker': [u'algo-2:2222'], u'master': [u'algo-1:2222']}, u'task': {u'index': 0, u'type': u'worker'}}\u001b[0m\n",
      "\u001b[35m2019-12-24 00:51:06,447 INFO - tf_container - creating an estimator from the user-provided model_fn\u001b[0m\n",
      "\u001b[35m2019-12-24 00:51:06,447 INFO - tensorflow - Using config: {'_save_checkpoints_secs': 300, '_keep_checkpoint_max': 5, '_task_type': u'worker', '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7ff8a70cefd0>, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 2, '_tf_random_seed': None, '_device_fn': None, '_num_worker_replicas': 2, '_task_id': 0, '_log_step_count_steps': 100, '_evaluation_master': '', '_eval_distribute': None, '_train_distribute': None, '_session_config': device_filters: \"/job:ps\"\u001b[0m\n",
      "\u001b[35mdevice_filters: \"/job:worker/task:0\"\u001b[0m\n",
      "\u001b[35mallow_soft_placement: true\u001b[0m\n",
      "\u001b[35mgraph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\u001b[0m\n",
      "\u001b[35m}\u001b[0m\n",
      "\u001b[35m, '_global_id_in_cluster': 1, '_is_chief': False, '_protocol': None, '_save_checkpoints_steps': None, '_experimental_distribute': None, '_save_summary_steps': 100, '_model_dir': u's3://sagemaker-us-east-2-371990375707/sagemaker-tensorflow-2019-12-24-00-47-51-105/checkpoints', '_master': u'grpc://algo-2:2222'}\u001b[0m\n",
      "\u001b[35m2019-12-24 00:51:06,449 INFO - tensorflow - Not using Distribute Coordinator.\u001b[0m\n",
      "\u001b[35m2019-12-24 00:51:06,449 INFO - tensorflow - Start Tensorflow server.\u001b[0m\n",
      "\u001b[35m2019-12-24 00:51:06,484 INFO - tensorflow - Waiting 5 secs before starting training.\u001b[0m\n",
      "\u001b[34m2019-12-24 00:51:09,829 INFO - tensorflow - loss = 2.2978892, step = 0\u001b[0m\n",
      "\u001b[35m2019-12-24 00:51:11,830 WARNING - tensorflow - From /opt/ml/code/mnist.py:114: string_input_producer (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[35mInstructions for updating:\u001b[0m\n",
      "\u001b[35mQueue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensor_slices(string_tensor).shuffle(tf.shape(input_tensor, out_type=tf.int64)[0]).repeat(num_epochs)`. If `shuffle=False`, omit the `.shuffle(...)`.\u001b[0m\n",
      "\u001b[35m2019-12-24 00:51:11,837 WARNING - tensorflow - From /usr/local/lib/python2.7/dist-packages/tensorflow/python/training/input.py:276: input_producer (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[35mInstructions for updating:\u001b[0m\n",
      "\u001b[35mQueue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensor_slices(input_tensor).shuffle(tf.shape(input_tensor, out_type=tf.int64)[0]).repeat(num_epochs)`. If `shuffle=False`, omit the `.shuffle(...)`.\u001b[0m\n",
      "\u001b[35m2019-12-24 00:51:11,838 WARNING - tensorflow - From /usr/local/lib/python2.7/dist-packages/tensorflow/python/training/input.py:188: limit_epochs (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[35mInstructions for updating:\u001b[0m\n",
      "\u001b[35mQueue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensors(tensor).repeat(num_epochs)`.\u001b[0m\n",
      "\u001b[35m2019-12-24 00:51:11,841 WARNING - tensorflow - From /usr/local/lib/python2.7/dist-packages/tensorflow/python/training/input.py:197: __init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[35mInstructions for updating:\u001b[0m\n",
      "\u001b[35mTo construct input pipelines, use the `tf.data` module.\u001b[0m\n",
      "\u001b[35m2019-12-24 00:51:11,843 WARNING - tensorflow - From /usr/local/lib/python2.7/dist-packages/tensorflow/python/training/input.py:197: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[35mInstructions for updating:\u001b[0m\n",
      "\u001b[35mTo construct input pipelines, use the `tf.data` module.\u001b[0m\n",
      "\u001b[35m2019-12-24 00:51:11,847 WARNING - tensorflow - From /opt/ml/code/mnist.py:86: __init__ (from tensorflow.python.ops.io_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[35mInstructions for updating:\u001b[0m\n",
      "\u001b[35mQueue-based input pipelines have been replaced by `tf.data`. Use `tf.data.TFRecordDataset`.\u001b[0m\n",
      "\u001b[35m2019-12-24 00:51:11,855 WARNING - tensorflow - From /opt/ml/code/mnist.py:119: batch (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[35mInstructions for updating:\u001b[0m\n",
      "\u001b[35mQueue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.batch(batch_size)` (or `padded_batch(...)` if `dynamic_pad=True`).\u001b[0m\n",
      "\u001b[35m2019-12-24 00:51:11,866 INFO - tensorflow - Calling model_fn.\u001b[0m\n",
      "\u001b[35m2019-12-24 00:51:12,197 INFO - tensorflow - Done calling model_fn.\u001b[0m\n",
      "\u001b[35m2019-12-24 00:51:12,199 INFO - tensorflow - Create CheckpointSaverHook.\u001b[0m\n",
      "\u001b[35m2019-12-24 00:51:12,507 INFO - tensorflow - Graph was finalized.\u001b[0m\n",
      "\u001b[35m2019-12-24 00:51:12,595 INFO - tensorflow - Running local_init_op.\u001b[0m\n",
      "\u001b[35m2019-12-24 00:51:12,601 INFO - tensorflow - Done running local_init_op.\u001b[0m\n",
      "\u001b[35m2019-12-24 00:51:12,635 WARNING - tensorflow - From /usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py:804: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[35mInstructions for updating:\u001b[0m\n",
      "\u001b[35mTo construct input pipelines, use the `tf.data` module.\u001b[0m\n",
      "\u001b[35m2019-12-24 00:51:13,185 INFO - tensorflow - loss = 0.35690913, step = 25\u001b[0m\n",
      "\u001b[35m2019-12-24 00:51:20,184 INFO - tensorflow - global_step/sec: 14.4943\u001b[0m\n",
      "\u001b[34m2019-12-24 00:51:22,373 INFO - tensorflow - loss = 0.042335093, step = 159 (12.544 sec)\u001b[0m\n",
      "\u001b[35m2019-12-24 00:51:26,997 INFO - tensorflow - global_step/sec: 14.8236\u001b[0m\n",
      "\u001b[35m2019-12-24 00:51:28,545 INFO - tensorflow - loss = 0.023074048, step = 249 (15.360 sec)\u001b[0m\n",
      "\u001b[35m2019-12-24 00:51:34,075 INFO - tensorflow - global_step/sec: 14.4125\u001b[0m\n",
      "\u001b[34m2019-12-24 00:51:35,040 INFO - tensorflow - loss = 0.059529636, step = 344 (12.668 sec)\u001b[0m\n",
      "\u001b[35m2019-12-24 00:51:40,864 INFO - tensorflow - global_step/sec: 14.8761\u001b[0m\n",
      "\u001b[35m2019-12-24 00:51:43,045 INFO - tensorflow - loss = 0.03360737, step = 464 (14.500 sec)\u001b[0m\n",
      "\u001b[34m2019-12-24 00:51:47,614 INFO - tensorflow - loss = 0.02540111, step = 530 (12.574 sec)\u001b[0m\n",
      "\u001b[35m2019-12-24 00:51:47,786 INFO - tensorflow - global_step/sec: 14.7355\u001b[0m\n",
      "\u001b[35m2019-12-24 00:51:54,622 INFO - tensorflow - global_step/sec: 14.9205\u001b[0m\n",
      "\u001b[35m2019-12-24 00:51:57,805 INFO - tensorflow - loss = 0.054063804, step = 681 (14.760 sec)\u001b[0m\n",
      "\u001b[34m2019-12-24 00:52:00,118 INFO - tensorflow - loss = 0.03847832, step = 715 (12.504 sec)\u001b[0m\n",
      "\u001b[35m2019-12-24 00:52:01,617 INFO - tensorflow - global_step/sec: 14.582\u001b[0m\n",
      "\u001b[35m2019-12-24 00:52:08,556 INFO - tensorflow - global_step/sec: 14.6999\u001b[0m\n",
      "\u001b[35m2019-12-24 00:52:12,576 INFO - tensorflow - loss = 0.03776071, step = 898 (14.771 sec)\u001b[0m\n",
      "\u001b[34m2019-12-24 00:52:12,719 INFO - tensorflow - loss = 0.0046073613, step = 901 (12.601 sec)\u001b[0m\n",
      "\u001b[35m2019-12-24 00:52:15,492 INFO - tensorflow - global_step/sec: 14.8503\u001b[0m\n",
      "\u001b[35m2019-12-24 00:52:19,567 INFO - tensorflow - Loss for final step: 0.005920945.\u001b[0m\n",
      "\u001b[34m2019-12-24 00:52:19,391 INFO - tensorflow - Saving checkpoints for 1001 into s3://sagemaker-us-east-2-371990375707/sagemaker-tensorflow-2019-12-24-00-47-51-105/checkpoints/model.ckpt.\u001b[0m\n",
      "\u001b[34m2019-12-24 00:52:21,190 INFO - tensorflow - Calling model_fn.\u001b[0m\n",
      "\u001b[34m2019-12-24 00:52:21,301 INFO - tensorflow - Done calling model_fn.\u001b[0m\n",
      "\u001b[34m2019-12-24 00:52:21,319 INFO - tensorflow - Starting evaluation at 2019-12-24-00:52:21\u001b[0m\n",
      "\u001b[34m2019-12-24 00:52:21,392 INFO - tensorflow - Graph was finalized.\u001b[0m\n",
      "\u001b[34m2019-12-24 00:52:21,438 INFO - tensorflow - Restoring parameters from s3://sagemaker-us-east-2-371990375707/sagemaker-tensorflow-2019-12-24-00-47-51-105/checkpoints/model.ckpt-1001\u001b[0m\n",
      "\u001b[34m2019-12-24 00:52:21,727 INFO - tensorflow - Running local_init_op.\u001b[0m\n",
      "\u001b[34m2019-12-24 00:52:21,736 INFO - tensorflow - Done running local_init_op.\u001b[0m\n",
      "\u001b[34m2019-12-24 00:52:22,322 INFO - tensorflow - Evaluation [10/100]\u001b[0m\n",
      "\u001b[34m2019-12-24 00:52:22,770 INFO - tensorflow - Evaluation [20/100]\u001b[0m\n",
      "\u001b[34m2019-12-24 00:52:23,211 INFO - tensorflow - Evaluation [30/100]\u001b[0m\n",
      "\u001b[34m2019-12-24 00:52:23,656 INFO - tensorflow - Evaluation [40/100]\u001b[0m\n",
      "\u001b[34m2019-12-24 00:52:24,104 INFO - tensorflow - Evaluation [50/100]\u001b[0m\n",
      "\u001b[34m2019-12-24 00:52:24,542 INFO - tensorflow - Evaluation [60/100]\u001b[0m\n",
      "\u001b[34m2019-12-24 00:52:24,987 INFO - tensorflow - Evaluation [70/100]\u001b[0m\n",
      "\u001b[34m2019-12-24 00:52:25,433 INFO - tensorflow - Evaluation [80/100]\u001b[0m\n",
      "\u001b[34m2019-12-24 00:52:25,874 INFO - tensorflow - Evaluation [90/100]\u001b[0m\n",
      "\u001b[34m2019-12-24 00:52:26,327 INFO - tensorflow - Evaluation [100/100]\u001b[0m\n",
      "\u001b[34m2019-12-24 00:52:26,355 INFO - tensorflow - Finished evaluation at 2019-12-24-00:52:26\u001b[0m\n",
      "\u001b[34m2019-12-24 00:52:26,355 INFO - tensorflow - Saving dict for global step 1001: accuracy = 0.9886, global_step = 1001, loss = 0.032463003\u001b[0m\n",
      "\u001b[34m2019-12-24 00:52:26,642 INFO - tensorflow - Saving 'checkpoint_path' summary for global step 1001: s3://sagemaker-us-east-2-371990375707/sagemaker-tensorflow-2019-12-24-00-47-51-105/checkpoints/model.ckpt-1001\u001b[0m\n",
      "\u001b[34m2019-12-24 00:52:26,894 INFO - tensorflow - Calling model_fn.\u001b[0m\n",
      "\u001b[34m2019-12-24 00:52:26,953 INFO - tensorflow - Done calling model_fn.\u001b[0m\n",
      "\u001b[34m2019-12-24 00:52:26,953 INFO - tensorflow - Signatures INCLUDED in export for Eval: None\u001b[0m\n",
      "\u001b[34m2019-12-24 00:52:26,953 INFO - tensorflow - Signatures INCLUDED in export for Classify: None\u001b[0m\n",
      "\u001b[34m2019-12-24 00:52:26,953 INFO - tensorflow - Signatures INCLUDED in export for Regress: None\u001b[0m\n",
      "\u001b[34m2019-12-24 00:52:26,954 INFO - tensorflow - Signatures INCLUDED in export for Predict: ['serving_default', 'predictions']\u001b[0m\n",
      "\u001b[34m2019-12-24 00:52:26,954 INFO - tensorflow - Signatures INCLUDED in export for Train: None\u001b[0m\n",
      "\u001b[34m2019-12-24 00:52:27,020 INFO - tensorflow - Restoring parameters from s3://sagemaker-us-east-2-371990375707/sagemaker-tensorflow-2019-12-24-00-47-51-105/checkpoints/model.ckpt-1001\u001b[0m\n",
      "\u001b[34m2019-12-24 00:52:27,288 WARNING - tensorflow - From /usr/local/lib/python2.7/dist-packages/tensorflow/python/estimator/estimator.py:1046: calling add_meta_graph_and_variables (from tensorflow.python.saved_model.builder_impl) with legacy_init_op is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mPass your op to the equivalent parameter main_op instead.\u001b[0m\n",
      "\u001b[34m2019-12-24 00:52:27,288 INFO - tensorflow - Assets added to graph.\u001b[0m\n",
      "\u001b[34m2019-12-24 00:52:27,288 INFO - tensorflow - No assets to write.\u001b[0m\n",
      "\u001b[34m2019-12-24 00:52:28,231 INFO - tensorflow - SavedModel written to: s3://sagemaker-us-east-2-371990375707/sagemaker-tensorflow-2019-12-24-00-47-51-105/checkpoints/export/Servo/1577148746/saved_model.pb\u001b[0m\n",
      "\u001b[34m2019-12-24 00:52:28,303 INFO - tensorflow - Loss for final step: 0.040664304.\u001b[0m\n",
      "\u001b[34m2019-12-24 00:52:28,599 INFO - tf_container - Downloaded saved model at /opt/ml/model/export/Servo/1577148746\u001b[0m\n",
      "\u001b[35m2019-12-24 00:52:29,721 INFO - tf_container - master algo-1 is down, stopping parameter server\u001b[0m\n",
      "\n",
      "2019-12-24 00:52:38 Uploading - Uploading generated training model\n",
      "2019-12-24 00:52:38 Completed - Training job completed\n",
      "Training seconds: 268\n",
      "Billable seconds: 268\n"
     ]
    }
   ],
   "source": [
    "# Create an estimator\n",
    "\n",
    "from sagemaker.tensorflow import TensorFlow\n",
    "\n",
    "mnist_estimator = TensorFlow(entry_point='mnist.py',\n",
    "                             role=role,\n",
    "                             framework_version='1.12.0',\n",
    "                             training_steps=1000, \n",
    "                             evaluation_steps=100,\n",
    "                             train_instance_count=2,\n",
    "                             train_instance_type='ml.c4.xlarge')\n",
    "\n",
    "mnist_estimator.fit(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The Python 2 tensorflow images will be soon deprecated and may not be supported for newer upcoming versions of the tensorflow images.\n",
      "Please set the argument \"py_version='py3'\" to use the Python 3 tensorflow image.\n"
     ]
    }
   ],
   "source": [
    "# SageMaker's transformer class\n",
    "\n",
    "transformer = mnist_estimator.transformer(instance_count=1, instance_type='ml.m4.xlarge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "............."
     ]
    }
   ],
   "source": [
    "# Run a batch transform job\n",
    "\n",
    "input_bucket_name = 'sagemaker-sample-data-{}'.format(region)\n",
    "input_file_path = 'batch-transform/mnist-1000-samples'\n",
    "\n",
    "transformer.transform('s3://{}/{}'.format(input_bucket_name, input_file_path), content_type='text/csv')\n",
    "\n",
    "transformer.wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sagemaker-us-east-2-371990375707/sagemaker-tensorflow-2019-12-24-00-47-5-2019-12-24-00-53-17-099\n"
     ]
    }
   ],
   "source": [
    "# Download the results\n",
    "\n",
    "print(transformer.output_path)\n",
    "\n",
    "# Now let's download the first ten results from S3:\n",
    "\n",
    "import json\n",
    "from six.moves.urllib import parse\n",
    "\n",
    "import boto3\n",
    "\n",
    "parsed_url = parse.urlparse(transformer.output_path)\n",
    "bucket_name = parsed_url.netloc\n",
    "prefix = parsed_url.path[1:]\n",
    "\n",
    "s3 = boto3.resource('s3')\n",
    "\n",
    "predictions = []\n",
    "for i in range(10):\n",
    "    file_key = '{}/data-{}.csv.out'.format(prefix, i)\n",
    "\n",
    "    output_obj = s3.Object(bucket_name, file_key)\n",
    "    output = output_obj.get()[\"Body\"].read().decode('utf-8')\n",
    "\n",
    "    predictions.extend(json.loads(output)['outputs']['classes']['int64Val'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7, 2, 1, 0, 4, 1, 4, 9, 5, 9\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAJEAAACRCAYAAADD2FojAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAABBNJREFUeJzt3L8rrXEAx/FzrmtQFkQZ/CiTRX6kFIosYuRfYJFFme1Gi7/AopRBkqIYMDAIiTAgKXUMKKHOXe7g83Sdzrmf8z2/er+2z+XyDO+evj0e4slkMgY4fuX7AlD8iAg2IoKNiGAjItiICDYigo2IYPudy28Wj8d5slnEkslk/F//zp0INiKCjYhgIyLYiAg2IoKNiGAjItiICDYigo2IYCMi2IgINiKCjYhgIyLYiAg2IoKNiGAjItiICDYigo2IYCMi2IgINiKCjYhgy+nv4oc2Pj4ue2JiQvbDw4Ps9/d32UtLS7IfHx9lX11duZdYkrgTwUZEsBERbPFc/jH00H+f6ObmRnZzc7P19V5eXmSfnZ1ZX891f38ve35+Xvbh4WHQ78/fJ0IwRAQbEcFWUs+Jos+F2traZJ+fn8tubW2V3dnZKXtgYEB2T0+P7Lu7O9kNDQ1pX2ssFot9fX3Jfnp6kl1fX5/y/9/e3soOfSb6CXci2IgINiKCraSeE2VbVVWV7Pb2dtlHR0eyu7u7M/r60Z/dXV5eyo6e4aqrq2VPTU3JXlxczOj7Z4rnRAiGiGAjItg4ExWQsbEx2cvLy7JPT09lDw4Oyk4kEmEu7C/ORAiGiGAjItg4E+VRXV2d7JOTk5Qfj75DvrKyEubCfsCZCMEQEWxEBFtJvU9UbKI/+6qtrZX9/Pws++LiIvg1/Q/uRLAREWxEBBvPiXKot7dX9vb2tuzy8nLZ0Xe8d3d3g1xXunhOhGCICDYigo3nRDk0MjIiO3oG2trakr2/vx/8mrKBOxFsRAQbEcHGmSigiooK2cPDw7I/Pj5kz83Nyf78/AxzYVnGnQg2IoKNiGDjTBTQ7Oys7I6ODtkbGxuy9/b2gl9TCNyJYCMi2IgINt4nyqLR0VHZq6urst/e3mRHnxsdHByEubAs4X0iBENEsBERbDwnMtTU1MheWFiQXVZWJnt9fV12oZ+B0sWdCDYigo2IYOM5UQaiZ5zomaarq0v29fW17OhzoejHCx3PiRAMEcFGRLDxnCgDLS0tsqNnoKiZmRnZxXYGShd3ItiICDYigo0zUQpNTU2yNzc3U35+9J3qtbW1rF9TIeJOBBsRwUZEsHEmSmFyclJ2Y2Njys/f2dmRncufS+YTdyLYiAg2IoKNM9E3fX19sqenp/N0JcWFOxFsRAQbEcHGmeib/v5+2ZWVlSk/P/p+0Ovra9avqRhwJ4KNiGAjItg4E2Xg+PhY9tDQkOxEIpHLyykY3IlgIyLYiAg2fhcfaeN38REMEcFGRLDl9EyE0sSdCDYigo2IYCMi2IgINiKCjYhgIyLYiAg2IoKNiGAjItiICDYigo2IYCMi2IgINiKCjYhgIyLYiAg2IoKNiGD7A0ic7WYQ5QUkAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 144x720 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAJEAAACRCAYAAADD2FojAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAABFtJREFUeJzt3c0rbHEcx/F7bpeyIhZSVsiCosTGWmw8pBTlv/BYUlbyJ9hZYCORyMKOLIyyQKnZKGxIUiIpD3O3vr/0mzn3M2fuzJz3a/e5nXvmLD79+vY7D4JUKvULUPz+3xeAwkeJIKNEkFEiyCgRZJQIMkoEGSWC7E8ufywIAnY2C1gqlQp++ndWIsgoEWSUCDJKBBklgowSQUaJIKNEkFEiyCgRZJQIspzeO8t3ExMTJpeVlZnc0tJi8tDQkPd8i4uLJh8dHZm8srIS9hLzEisRZJQIMkoEWZDLlxfz7XmitbU1k9PNOKrLy0uTu7q6TL65uYn091U8T4TIUCLIKBFksdonUmegZDJp8t7ensl1dXUm9/X1mVxfX2/y6OioyQsLC6GuJ1+wEkFGiSCjRJAV9UzU3t5u8uDgoPf4i4sLk/v7+01+eHgw+eXlxeTS0lKTE4mEya2trSZXVVV5r6dQsBJBRokgo0SQFfVMVFNTY3IQ2Fs/7gzU09Nj8u3tbajfGx8fN7mpqcl7/O7ubqjz5ytWIsgoEWSUCLKinol2dnZMbmhoMPn5+dnkx8dH6fdGRkZMLikpkc5XKFiJIKNEkFEiyIp6JnJdX19n9XyTk5MmNzY2eo8/Pj725kLFSgQZJYKMEkEW6/fOwurt7TV5fX3dZPd5ovv7e5PdfaSDg4MsXl30eO8MkaFEkFEiyGK1T6Ryn9l2ZyCX+55boc1AmWIlgowSQUaJIGMm8tja2jK5u7vbe/zy8rLJs7OzWb+mfMRKBBklgowSQca9s2/c99TOzs5Mdt+dd9/N7+zsNNn9RmOh494ZIkOJIKNEkLFP9M3GxobJ6b4ftLq6anKxzUCZYiWCjBJBRokgi/VM5H6Tsa2tzXv8/v6+yXNzc9m+pILESgQZJYKMEkEWq5nI3feZmZkxOd33hE5PT012v2MdV6xEkFEiyCgRZLGaidzvTHd0dHiPd5+xZl/oZ6xEkFEiyCgRZLF6xvrt7c3kdPtCtbW1Jof9Wx/FhmesERlKBBklgixW+0RhVVZWmvz+/i6d7+npyXs+d0YrLy/3nq+iosLksbGxUNfz+flp8vT0tMmvr68ZnYeVCDJKBBklgoyZyOP8/Dyr53O/e+3uO1VXV5s8PDyc1d9P5+7uzuT5+fmM/h8rEWSUCDJKBFms7p1tbm6aPDAw8J+u5N98fHyY/PX15T1+e3vb5JOTE+/xh4eHJicSCZO5d4bIUCLIKBFksZqJXFNTUyaH/Tv2zc3NJofd11laWjL56urKe7z7/aRkMhnq91TMRIgMJYKMEkEW65kI4TATITKUCDJKBBklgowSQUaJIKNEkFEiyCgRZJQIMkoEGSWCjBJBRokgo0SQUSLIKBFklAgySgRZTp+xRnFiJYKMEkFGiSCjRJBRIsgoEWSUCDJKBBklgowSQUaJIKNEkFEiyCgRZJQIMkoEGSWCjBJBRokgo0SQUSLIKBFklAiyvzWV/Phq4PCkAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 144x720 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAJEAAACRCAYAAADD2FojAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAA1FJREFUeJzt3bEupFEYx+GdtRo6CdFRCQlBopCQaFSi0apcgMR9aF2CSiJRiNBSaihFpVBRqIiG2WIbZ7KZkP98386s5+les4lT/PLm5JsZ22g2mz8g8fNfH4DeJyJiIiImImIiIiYiYiIiJiJiv+r8ZY1Gw5PNHtZsNht/+7lNRExExERETETERERMRMRERExExERETETERERMRMRERExExERErNbPE313ExMTxXxzc1PMOzs7xby3t1f5mTrBJiImImIiIuZOVKP5+flifn9/L+b7+/s6j9MxNhExERETETF3ohrNzc0V8/PzczEfHR3VeZyOsYmIiYiYiIi5E1Voenq6mLe3t4t5f3+/zuNUxiYiJiJiIiLmTlShycnJYh4cHCzmg4ODOo9TGZuImIiIiYhYo87/IOa7/c3Gy8vLYh4eHi7m1udIre+ldRt/s5HKiIiYiIh5TtRB4+PjxbywsFDMt7e3xdztd6DPsomIiYiYiIi5E3XQyspK29cfHx9rOkm9bCJiIiImImLuRB00MzPT9vXd3d2aTlIvm4iYiIiJiJjPEwUWFxeL+eTkpJjv7u6KeWlpqZhfX18rOVdVfJ6IyoiImIiIeU4UWF1dLeahoaFiPjs7K+ZeuwN9lk1ETETERETMnSgwOztbzK3P3A4PD+s8zj9jExETETEREfPe2ReMjo4W8/X1dTE/PT0V89TUVOVnqpP3zqiMiIiJiJjnRF+wtbVVzCMjI8V8enpa42m6h01ETETERETMnegLxsbG2r7e+pzou7CJiImImIiIuRN9wfr6etvXj4+PazpJd7GJiImImIiIuRO1sby8XMytnyfiD5uImIiIiYiYO1EbGxsbxdzX11fMV1dXxXxxcVH5mbqRTURMRMRERMyd6IOBgYFiXltba/vvW79r//b21vEz9QKbiJiIiImImO/if9Df31/M5+fnxfzw8FDMm5ubxfzy8lLNwbqE7+JTGRERExExdyI+zZ2IyoiImIiIiYiYiIiJiJiIiImImIiIiYiYiIiJiJiIiImImIiI1fp5Iv5PNhExERETETERERMRMRERExExERETETERERMRMRERExExERETETERERMRMRERExExERETETERERMRsd9Ok5Iff4Yo0QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 144x720 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAJEAAACRCAYAAADD2FojAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAABH1JREFUeJzt3b8r7XEcx/F7uJuVxcKgyGbAdpSJQZ1FlKQMfiTHTomVMjmRzR9gkQwWJWVhsDApLBIGJSlx7nTL+311vvfr9f1+D9/zfGyv27nf8xle99O77/dzvjdTLBZ/AYqqci8APx8lgowSQUaJIKNEkFEiyCgRZJQIst9Jflkmk+HO5g9WLBYzn/05OxFklAgySgQZJYKMEkFGiSCjRJBRIsgoEWSUCDJKBBklgowSQUaJIKNEkCV6nuinq6mpMXl5ednk8fFxk09OTkzu7+83+erqKsLVlQ87EWSUCDJKBFkmyRc6/PQz1k1NTSafn5+X/HxVlf03ms/nTS4UCtEsLCGcsUZsKBFklAgy7hOVUFdXZ/Lm5maZVvK9sRNBRokgo0SQMRN94O/j5HI5kzs6OqTrZ7NZk/19pNPTU5MPDg6k70sKOxFklAgySgQZz84+eHt7M/n9/V26np95gq7nzxcNDAyY7M8nJY1nZ4gNJYKMEkFW0TPR7u6uyb29vSarM9HDw4PJT09PJjc0NIS6XnV1tbQeFTMRYkOJIKNEkFXUs7Ouri6Tm5ubTfYzUNiZaH193eS9vT2THx8fTe7u7jZ5bm6u5PUnJydNXltbC7W+uLATQUaJIKNEkKX6PlFjY6PJR0dHJtfW1poc9KzLP9va2toyeXFx0eTn5+eS6/P3ifz6/Bnvl5cXk+fn501eXV01+fX1teT3h8V9IsSGEkFGiSBL9Uyk/nZ+f3/f5MHBQZPv7++F1f1renra5JWVFZODZraWlhaTLy4uIlwdMxFiRIkgo0SQVdSzsyDHx8cmj46Omhz1DORtb2+bPDQ0ZHJ7e3us3/9V7ESQUSLIKBFkFTUT+fssXmdnZ0Ir+VwmY2/D+PUGrX9hYcHk4eHhSNYVhJ0IMkoEGSWCLNUz0cTEhMnq78ji1tfXZ3JbW5vJQWfA/UyUFHYiyCgRZJQIslTPRH7GKDd/Zrq1tdXk2dnZUNe7u7szOeoz1f+LnQgySgQZJYIs1TPRd+N/az81NRXq719eXpo8MjJi8vX19ZfWpWIngowSQUaJIGMmipF/J6R/H1JYZ2dnJh8eHkrXiwo7EWSUCDJKBFmqZ6KgM8uef4+1t7GxYXJ9fX3Jz4f9vz2CfLdngX+xE0FGiSCjRJCleiby73leWloq+fmdnR2Tg2aYsDOO+l7s74qdCDJKBBklgizV72wM+57oqO/r+Ovd3t6a7N8hOTY2ZvLNzY3JQe/FjhvvbERsKBFklAiyVM9EXjabNTmXy5k8MzNjctQzUT6fN7lQKEjXTxozEWJDiSCjRJBV1EwUpKenx2R/38af5/Hvnfbnjfx5Jn9Guly/E/sqZiLEhhJBRokgYybCf2MmQmwoEWSUCDJKBBklgowSQUaJIKNEkFEiyCgRZJQIMkoEGSWCjBJBRokgS/Q8EdKJnQgySgQZJYKMEkFGiSCjRJBRIsgoEWSUCDJKBBklgowSQUaJIKNEkFEiyCgRZJQIMkoEGSWCjBJBRokgo0SQUSLI/gDAMTCc/DHSSAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 144x720 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAJEAAACRCAYAAADD2FojAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAABEpJREFUeJzt3b8r7XEcx3HfmyKSSEoWYZAksVBKFkQmlDIx+AOsTJgMRmaTRTYzgw1lUBYsRj9SyCDOHe7tdt9vxzl4+X7O8T3Px/a6R9ebXn18Ot/P93uiVCpVBCh+5XoA/HyUCDJKBBklgowSQUaJIKNEkFEiyIpDfrMoinhn8wdLpVJRun9nJYKMEkFGiSCjRJBRIsgoEWSUCDJKBBklgowSQUaJIKNEkFEiyCgRZJQIMkoEGSWCjBJBRokgC3rGOt91dnaavL29bXJDQ0PAaYqKBgYGTD49PTX58vIy5DjvYiWCjBJBRokgY0/0n8HBQZNLSkpyNMkfo6OjJs/MzJg8OTkZcpx3sRJBRokgo0SQFfSeqLjY/vjDw8M5miS9o6Mjk+fm5kwuLy83+fHxMfaZ0mElgowSQUaJICvoPVF/f7/JPT09Jq+srIQc542qqiqTW1tbTS4rKzOZPRF+LEoEGSWCLAr5ATG5fmZjW1ubyXt7eybf3NyY3NXVZfLDw0Msc73Hz9fb22tyXV2dyVdXV7HOwzMbERtKBBklgqyg3idaWFgw2V97GhoaMjn0Hqi6utrkvr4+k19fX0OO82GsRJBRIsgoEWSJ3hONj4+b7M8LnZ2dmXx4eBj7TJnMz8+b7PdA/n2ju7u7uEf6EFYiyCgRZJQIskTviSYmJkz252/W1tZCjvOGv7d/amrK5JeXF5OXl5dNfn5+jmWuz2IlgowSQUaJIEvUnqiystLk7u7ujF+/vr4e5zhZzc7OmlxTU2Oyfx7R7u5u7DN9BSsRZJQIMkoEWaL2RP55QvX19SZvbm6GHCerpqamjK+fnJwEmkTDSgQZJYKMEkGWqD3R/f29ycfHxya3t7eb7M80397exjPYX7W1tSb7807e/v5+nON8G1YiyCgRZJQIskTtiZ6enkw+Pz83eWxszOSdnR2TV1dXpe/v7/VvbGw02Z8fyvYchHy9z8xjJYKMEkFGiSBL9POJWlpaTF5cXDR5ZGTEZPWzPK6vr032v1t/XiiK0j7u55+KigqT/Z4vNJ5PhNhQIsgoEWSJ3hNl09HRYXJzc7P0/21tbWV8fWNjw2R/n5nnP3sk19gTITaUCDJKBFl+/dENzJ838vm7XVxcfOrr/bW4fD1zzUoEGSWCjBJBVtB7otD8tbJs187ydQ/ksRJBRokgo0SQsScKyF+nDHndMk6sRJBRIsgoEWTsiQIqLS3N+Hquz1B/FSsRZJQIMkoEGXuigKanp032n1e2tLQUcpxvw0oEGSWCjBJBxp4ooIODA5P985Dy9bM7smElgowSQUaJICvoe/HxOdyLj9hQIsgoEWSUCDJKBBklgowSQUaJIKNEkFEiyCgRZEGvnSGZWIkgo0SQUSLIKBFklAgySgQZJYKMEkFGiSCjRJBRIsgoEWSUCDJKBBklgowSQUaJIKNEkFEiyCgRZJQIMkoEGSWC7DcpyNZz0Np/RQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 144x720 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAJEAAACRCAYAAADD2FojAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAA2dJREFUeJzt3TEvrFkcx/EdWZEoaRUSLR2NiFal4mV4B16FCrVCK0oqhQqJQqmhlqAywZhtnSe7c3f2N2fM7P18uv81ck/xdfLkOfPMtLrd7h+QmPjpBTD+RERMRMRERExExERETETERETsz2H+Z61Wy53NMdbtdlt/9+92ImIiIiYiYiIiJiJiIiImImIiIiYiYiIiJiJiIiImImIiIiYiYiIiJiJiIiImImJDfY/1725zc7OYT09Pi3lnZ6eYDw4OirnT6dRZWMhORExExERErDXMD7n63Z47m52dLebb29tinpub6/n709PTxfz29jaYhf1HnjujGhERExEx94kqWl9fL+ZfXQMdHx8Xc7vdHviaarATERMRMRERc000QFNTU8W8u7vb1+8fHR0V87h8UL2diJiIiImImLOzAVpeXi7mq6urnq///Pws5snJyYGvaZCcnVGNiIiJiJj7RAO0tbXV1+vPzs4qrWS47ETERERMRMRcEw1Q8/1DTe/v78Xc79naqLITERMRMRERc3YWWF1dLebLy8uer39+fi7mmZmZga+pJmdnVCMiYiIi5j5RYGVlpa/X7+/vV1rJz7ITERMRMRERc00UaL6nuunl5aWYXRPBPxARMRERc3bWh7W1tWK+uLgo5omJ8m/y4eGhmOfn56usa1icnVGNiIiJiJj7RH1ofi518xqo6fz8vOZyRoadiJiIiImImGuiPmxvb/f8efOs7PDwsOZyRoadiJiIiImImLOzHprfxdE8C2veJ7q7uyvmpaWlOgv7Ic7OqEZExEREzH2iHprP2v/qrOzk5KTmckaWnYiYiIiJiJhroh6a7x9qenp6Kua9vb2ayxlZdiJiIiImImKuiXrY2Njo+fPHx8difn19rbmckWUnIiYiYiIi5prom+Z3sC4sLPR8fbvdLuaPj4+Br2kc2ImIiYiYiIi5Jvrm6+urmK+vr4t5cXGxmO/v76uvaRzYiYiJiJiIiLkm+qbT6RRz8ztam8/o3dzcVF/TOLATERMRMRER8yw+/5pn8alGRMRERExExERETETERERMRMRERExExEREbKhnZ/w/2YmIiYiYiIiJiJiIiImImIiIiYiYiIiJiJiIiImImIiIiYiYiIiJiJiIiImImIiIiYiYiIiJiJiIiP0Fjs+mq5B5ClMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 144x720 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAJEAAACRCAYAAADD2FojAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAABIdJREFUeJzt3U0ovGscxvEzp7NRpJG37NiKlI2Ft5WXLGVFiAUpCwspyYK1LaUUsfFSLIhkZWFHpNkhUYRE2RFztud3d5r/zP+a+zGe//ezu5gxN13d/XrmnkckHo//BSj+/u4F4OejRJBRIsgoEWSUCDJKBBklgowSQfZPkC8WiUS4svmDxePxyP99nZ0IMkoEGSWCjBJBRokgo0SQUSLIKBFklAgySgQZJYKMEkFGiSCjRJBRIsgoEWSUCDJKBBklgizQM9aZprCw0OS1tTWTj46OTJ6fnzf5+vray7qSlZuba3J9fb3Je3t7Jn98fHhZBzsRZJQIMkoE2R81E0WjUZNjsZjJ7ozx8PBgcqbNQMfHxyYXFBSYXF1dbfLFxYWXdbETQUaJIKNEkIV6JsrPzzd5dXXV5Ly8PJNnZ2dNHh4e9rOw3zQxMWFyaWmpyQMDAyb7moFc7ESQUSLIKBFkkSBvhh70/YmamppM3t3dTfj44uJik5+entK+plSUl5ebfH5+bvLm5qbJvb29Jr+9vaV1PdyfCN5QIsgoEWShuk7kng9qb29P+Pj+/n6TM20GOjg4SPh4dyZK9wyULHYiyCgRZJQIslDNRDMzMyZ3dXWZ7J6/WV9f976mVNTV1ZlcVFRk8uLioskrKyu+l5QUdiLIKBFklAiyUM1E7vuAX19fJt/d3Zn8/v7ufU3/lZWVZfL4+LjJQ0NDJru/T19fn5+FidiJIKNEkFEiyEI1E/1KW1ubyfv7+ya/vr6aPDc3J71eQ0ODyY2NjSbX1NQkfP7Gxob0+kFhJ4KMEkFGiSAL1Rlr97PnW1tbJpeUlCR8fiRijxCrf5tUf97V1ZXJLS0tJl9eXkrrUXHGGt5QIsgoEWShuk7knheqrKw0uaqqymR35hgdHTXZPXO9tLSU0nqWl5dNPjs7S/h49x6R3z0DJYudCDJKBBklgixU14kyTVlZmcnu/YJOT09Nbm5uNvm7Pwfn4joRvKFEkFEiyEJ1nSjTTE5OmuzOn2NjYyZn2gyULHYiyCgRZJQIMmaiNOro6DC5u7vbZPf+Qc/Pz97XFAR2IsgoEWSUCDJmojRqbW1N+P3t7W2TT05OfC4nMOxEkFEiyCgRZJwnSqP7+3uTs7OzTXY/m//TZiLOE8EbSgQZJYKM60SCwcFBk937Tj8+Ppr802agZLETQUaJIKNEkDETCdyZyL3mtrOzk/D5OTk5JkejUZNvbm6E1QWHnQgySgQZJYKMmcijz89Pkzs7O00eGRkxORaLmdzT0+NnYWnGTgQZJYKMEkHGeSKBe3+hiooKk391H+uFhQWTp6enTb69vVWXmFacJ4I3lAgySgQZM5GgtrbW5KmpKZMPDw9Ndv9/2svLi8lB/0/aVDETwRtKBBklgoyZCEljJoI3lAgySgQZJYKMEkFGiSCjRJBRIsgoEWSUCDJKBFmg750hnNiJIKNEkFEiyCgRZJQIMkoEGSWCjBJBRokgo0SQUSLIKBFklAgySgQZJYKMEkFGiSCjRJBRIsgoEWSUCDJKBBklguxfTHkivWk8MF0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 144x720 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAJEAAACRCAYAAADD2FojAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAABKZJREFUeJzt3UsorXscxvG9dArlElIGLuVSFEWRjEyUpJRyX8lIKYwMyEBRMjCgDA0M3FISZSQzKTOhDESZKBRRQgzWmZzB+f07ezmrx7ustd/vZ/bsvde73vTsf7/+70UgFAr9AhQJP30CiH+UCDJKBBklgowSQUaJIKNEkFEiyP6K5pcFAgF2NuNYKBQK/NefsxJBRokgo0SQUSLIKBFklAgySgQZJYKMEkFGiSCjRJBRIsgoEWSUCDJKBBklgowSQUaJIKNEkFEiyCgRZJQIMkoEWVSfO4s3aWlpJs/MzJhcXl5uckNDg8mfn5/enFiMYSWCjBJBRokgYyb6l2AwaPL09LTJeXl5YT/vzlAPDw/fc2IxjpUIMkoEGSWCLBDNl6HH2vuJcnNzTT4+PjY5KyvL5K9+VhsbGyYPDQ2Z/Pj4GOkpxhTeTwTPUCLIKBFkvp6J5ufnTR4eHjY5ELAjQKQ/q+fnZ5PdfaeFhQWTPz4+Ijp+tDETwTOUCDJKBJmvZqKCggKTT09PTU5JSTH57OzM5Lu7O5Pd+4e+cn9/b3JVVZXJt7e3ER0v2piJ4BlKBBklgsxX9xNVVlaanJqaavLBwYHJ9fX1JiclJZnc3d1t8vj4uMlFRUUm5+TkmLyzs2NyU1OTyfFyrY2VCDJKBBklgsxXM1FiYqLJ7h7Z3Nxc2M+/v7+bvLS0ZHJ7e7vJhYWFYY/3+vpqcqxfO/sdViLIKBFklAgyX81E7r6Oq7m52eTt7e2Ijl9dXR3Rvz86OjL55eUlos/HClYiyCgRZJQIMl/NROvr6ya3tLSYXFNTY3JpaanJFRUVJre2tpqckZFh8tPTU9i/7+/vN3l5ednk8/PzX/GAlQgySgQZJYLMV/dYZ2Zmmnx5eWlyenq6yZE+d7a/v2/y4OCgybu7uyaXlJSYvLi4aPLAwEDY74s27rGGZygRZJQIMl/tE7n3LHd0dJi8ublpsjsjudxn6UdHR0127z/a2toyeWxszOTGxkaT3Xu0r66uwp7PT2ElgowSQUaJIPPVPtFX3Gfre3p6THavhU1MTJj81f1AycnJJq+trZnsXstbWVkxua+vL+zxvcY+ETxDiSCjRJAxE/2grq4uk1dXV02+ubkx2X2XQLSf1WcmgmcoEWSUCDJmoh+UkGD/D7v7Qp2dnSZPTk6aPDU15c2J/QYzETxDiSCjRJAxE8UQdx/o8PDQZPedkWVlZSZfXFx4c2L/YCaCZygRZJQIMmaiGDYyMmLy7Oysye492729vSa/vb196/kwE8EzlAgySgQZM1EMy87ONtndNyouLjbZ3Wdyf5+bipkInqFEkFEiyJiJ4kh+fr7J19fXJrvvpAwGg9/6/cxE8AwlgowSQcZMFMf29vZMrqurM7m2ttZk9b3YzETwDCWCjBJB5qt3Nv5p2traTD45OTHZvbbm1e8KYSWCjBJBRokgY58I/xv7RPAMJYKMEkFGiSCjRJBRIsgoEWRR3SfCn4mVCDJKBBklgowSQUaJIKNEkFEiyCgRZJQIMkoEGSWCjBJBRokgo0SQUSLIKBFklAgySgQZJYKMEkFGiSCjRJBRIsj+BvizORPva8/eAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 144x720 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAJEAAACRCAYAAADD2FojAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAABKZJREFUeJzt3c8rbH8cx/E7fjaxEbHxq0w2FgglpaYsldhIYjkrCz9W7CiU/AOKWCh7SkmUklAKRUkWyAobC0lhvqvv4v2517in15wxx30+dq/rOufUfd1P7875nJlQPB7/BSgyvvsCEHyUCDJKBBklgowSQUaJIKNEkFEiyLJSebJQKMSdzQCLx+OhP/05KxFklAgySgQZJYKMEkFGiSCjRJBRIsgoEWSUCDJKBBklgowSQUaJIKNEkKV0PxGsgoICk8vLyz39/s3NjcnDw8Mmn52dmXx5eWny6empp/N9hpUIMkoEGSWCjJnIR+3t7SZ3dHSYHI1GTY5EIp6O7844FRUVJufm5ib8/czMTE/n+wwrEWSUCDJKBFkolR9yFfT3zqqqqkweGBgwORaLmRwOh00Ohf742ta38ToT8d4ZfEOJIKNEkHGfyIPS0lKTBwcHU3r+i4sLk8/Pz1N6/s+wEkFGiSCjRJD9UzNRUVGRye5Ms7e3Z/LGxobJr6+vJj89PZn8/Pxscl5ensmbm5smu/t9Dg8PTT4+Pjb55eUl4fm+CysRZJQIMkoE2Y9+dubOJLu7uybX1taa3NXVZfLa2lrC41dWVpp8fX1tsrtn+u7uzuSPj4+Ex083PDuDbygRZJQIsh91nygnJ8fklZUVk90ZaHp62uStrS1P53NnINft7a2n4wUVKxFklAgySgRZoO8T5efnmzw2Nmby6OioyY+PjyZXV1eb7D4Lg8V9IviGEkFGiSAL9H2izs5Ok90ZyL1P09raajIzUHKwEkFGiSCjRJAFeiZqaWlJ+HN3j7K7nwfJwUoEGSWCjBJBFuhnZ/f39yYXFhaa7L4nNjMzY/Lq6qrJJycnSby6n4dnZ/ANJYKMEkEW6JnIvXav73G5f39ubs7kg4MDk933yK6urkz+6vOCampqTN7f3zc53e9jMRPBN5QIMkoEWaBnotnZWZNHRkaSeXjfPTw8mLyzs2NyT09PCq/ma8xE8A0lgowSQRbomcj9bor6+nqT3Xfxs7Ls9qmysjKTMzK+9/+U+28xPj5u8uTkZAqv5nfMRPANJYKMEkEW6D3W7+/vJh8dHZnsvmvvamtrMzk7O9tkdyZpamryeIXeuN+H1tDQ4Ov5koWVCDJKBBklgizQM5Fqe3s74c/r6upMdmeit7c3k5eWlkyen583eWhoyOTe3t6/us50x0oEGSWCjBJB9k/PRF9xv59samrKZPdZXCwWMzkSiZgcjUY9nT/d91z/j5UIMkoEGSWCLND7ifwWDodNXlxcNLm7u1s6vvvsb3193eS+vj6Tv/s7X9lPBN9QIsgoEWTMRB6UlJSYvLCwYHJjY6PJxcXFJrvfj7a8vGyyu38p3TATwTeUCDJKBBkzURL19/eb3NzcbPLExITJ7mdOpjtmIviGEkFGiSBjJsJfYyaCbygRZJQIMkoEGSWCjBJBRokgo0SQUSLIKBFklAgySgQZJYKMEkFGiSBL6X4i/EysRJBRIsgoEWSUCDJKBBklgowSQUaJIKNEkFEiyCgRZJQIMkoEGSWCjBJBRokgo0SQUSLIKBFklAgySgQZJYKMEkH2H19mMzKEFHN1AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 144x720 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAJEAAACRCAYAAADD2FojAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAABQtJREFUeJzt3U8oZX0cx/Hn8ogRGpeiDDYWlLDQUDbSbCjKn2JhaWEiokhWip2SnT8LydTMcnbTlGSBjbIY0ySllJL8KzXkv/uspp7vr6dzh49jnnvv+7X7TO65x/SZ33z7nXPvCYRCob8ARdyfPgFEPkoEGSWCjBJBRokgo0SQUSLIKBFkf7/kmwUCAXY2I1goFAr815+zEkFGiSCjRJBRIsgoEWSUCDJKBBklgowSQUaJIKNEkFEiyCgRZJQIMkoEGSWCjBJBRokgo0SQUSLIKBFklAgySgQZJYKMEkFGiSCjRJC96Gfxo01BQYHJmZmZJjc2NppcXV1t8sPDg8nT09Mmr62tmbyzs/OU0/QdKxFklAgySgRZ4CW/DD3Svp+ouLjY5O7ubpObmppMdmci1d3dncnb29smr66umtzb22vyzc3Ns54P308E31AiyCgRZDG9T1RSUmJyV1eXya2trSanpaV5Hm9/f9/klZUVk3d3d00eHBw0eWNjw+S3b9+aHAwGTa6rqzP527dvJrv7Tn5hJYKMEkFGiSCLqX2imZkZk91rW+H2eZaWlkz+/v27ycPDwyZfXV15Hm95ednk9+/fmzw3N2dyWVmZyYeHhybn5eWZnJ2dbfLx8bHn+YTDPhF8Q4kgo0SQRdU+UVJSksnuPkxHR4fJgYD9L96dGaampkweHx83+eLi4knn+UtGRobJ8fHxJo+MjJj89etXk/Pz86X3fy6sRJBRIsgoEWRRNRO59zAPDAyY7M5A7rWu5uZmk9fX16XzcWec3NxckxcWFkz+8uWLyenp6Z7Hd3+fDx8+mHx2dvZb56liJYKMEkFGiSCLqpnInUHu7+89f969h7miosLklpYWkwsLCz2Pd3l5aXJRUZFnPjk5MTkrK8vz+C732tnY2JjJt7e3jzreU7ESQUaJIKNEkEXV/USvXr0y+ePHjya/e/fO5OTkZJPj4uy/qXB/N+7M5c5kKvez+p8/fza5p6fH5IODg2d9fxf3E8E3lAgySgRZVM1E4bx+/drkoaEhk6uqqkw+PT01eW9vz+TExESTS0tLTXY/N/ZY7ufG3Hu4X+ra2C/MRPANJYKMEkEWUzOR39z7g9rb2z1//ufPnyb39/ebPD8/b3K4a4F+YyaCbygRZJQIsqi6n+iluZ9ra2tre9TrOzs7Tf706ZN8Tn8CKxFklAgySgQZ+0SP4H6Wf2JiwuSUlBTP1//48cPk8vJyk6+vr4Wz8x/7RPANJYKMEkHGTOTBvR9ocXHR5NTUVM/Xn5+fm1xbW2uy+zyz/ztmIviGEkFGiSDj2pmH+vp6k8PNQO53ODY0NJgcaTPQ72IlgowSQUaJIGOf6F/cmcf9/qCEhATP18/Ozprs3i8U6dgngm8oEWSUCLKYnonc+3+2trZMzsnJ8Xz95uamyZWVlSaHe95ZpGEmgm8oEWSUCLKYvnZWU1Nj8ps3b0wONy/29fWZHG0z0O9iJYKMEkFGiSCL6ZlodHTU5HAzkPsMWPe59rGKlQgySgQZJYIspmeiYDBosvtM1aOjI5MnJyd9P6dIxEoEGSWCjBJBFtMzkfv9Qm5295H8fp5YpGIlgowSQUaJIIvpe6zxONxjDd9QIsgoEWQvOhMhOrESQUaJIKNEkFEiyCgRZJQIMkoEGSWCjBJBRokgo0SQUSLIKBFklAgySgQZJYKMEkFGiSCjRJBRIsgoEWSUCDJKBNk/I0hHrfGPQC8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 144x720 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# For demonstration purposes, we're also going to download the corresponding original input data so that we can see how the model did with its predictions.\n",
    "\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy import genfromtxt\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (2,10)\n",
    "\n",
    "def show_digit(img, caption='', subplot=None):\n",
    "    if subplot == None:\n",
    "        _,(subplot) = plt.subplots(1,1)\n",
    "    imgr = img.reshape((28,28))\n",
    "    subplot.axis('off')\n",
    "    subplot.imshow(imgr, cmap='gray')\n",
    "    plt.title(caption)\n",
    "\n",
    "tmp_dir = '/tmp/data'\n",
    "if not os.path.exists(tmp_dir):\n",
    "    os.makedirs(tmp_dir)\n",
    "\n",
    "for i in range(10):\n",
    "    input_file_name = 'data-{}.csv'.format(i)\n",
    "    input_file_key = '{}/{}'.format(input_file_path, input_file_name)\n",
    "    \n",
    "    s3.Bucket(input_bucket_name).download_file(input_file_key, os.path.join(tmp_dir, input_file_name))\n",
    "    input_data = genfromtxt(os.path.join(tmp_dir, input_file_name), delimiter=',')\n",
    "\n",
    "    show_digit(input_data)\n",
    "    \n",
    "\n",
    "print(', '.join(predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow_p36",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
